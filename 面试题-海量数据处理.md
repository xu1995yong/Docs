## 布隆过滤器
原理：当一个元素被加入集合时，通过K个Hash函数将这个元素映射成一个比特数组（Bit array）中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检索元素一定不在；如果都是1，则被检索元素很可能在。

初始状态时，Bloom Filter是一个包含m位的位数组，每一位都置为0。

![img](https://p-blog.csdn.net/images/p_blog_csdn_net/jiaomeng/275417/o_bf1.jpg)

为了表达S={x1, x2,…,xn}这样一个n个元素的集合，Bloom Filter使用k个相互独立的哈希函数，这k个相互独立的哈希函数分别将集合中的每个元素映射到{1,…,m}的范围中。对任意一个元素x，第i个哈希函数映射的位置hi(x)就会被置为1（1≤i≤k）。

![img](https://p-blog.csdn.net/images/p_blog_csdn_net/jiaomeng/275417/o_bf2.jpg)

    在判断y是否属于这个集合时，我们对y应用k次哈希函数，如果所有hi(y)的位置都是1（1≤i≤k），那么我们就认为y是集合中的元素，否则就认为y不是集合中的元素。 

## BIT-MAP





## 常见面试题
### 海量日志数据，提取出某日访问百度次数最多的那个IP

- 算法思想：分而治之+Hash

  1. 可以考虑采用“分而治之”的思想，按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址；
  2. 对于每一个小文件，可以构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址；
  3. 可以得到1024个小文件中的出现次数最多的IP，再依据常规的排序算法得到总体上出现次数最多的IP；

### 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？

- 方法一：
    1. 遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到相应的1000个小文件中（记为a0,a1,a2···）。这样每个小文件的大约为300M。
    2. 遍历文件b，采取和a相同的方式将url分别存储到1000小文件中（记为b0,b1,b2···）。这样处理后，所有可能相同的url都在对应的小文件（a0和b0,a1和b1，）中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。
    3. 求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。

- 方法二：如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）

### 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。

- 方法一：
	1. 顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件（记为a0,a1,····,a9）中。这样新生成的文件每个的大小大约也1G。
	2. 找一台内存在2G左右的机器，依次对a0,a1,····,a9用hash_map(query, query_count)来统计每个query出现的次数。利用快速/堆/归并排序按照出现次数进行排序。将排序好的query和对应的query_cout输出到文件中。这样得到了10个排好序的文件b0,b1,b2,b9。
	3. 对这10个文件进行归并排序（内排序与外排序相结合）。

### 在2.5亿个整数中找出不重复的整数，内存不足以容纳这2.5亿个整数。

采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存2^32*2bit=1GB内存。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。
