## 进程调度算法

### 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1.1 先来先服务 first-come first-serverd（FCFS）**

按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**1.2 短作业优先 shortest job first（SJF）**

按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

按估计剩余时间最短的顺序进行调度。

### 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**2.1 时间片轮转**

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

![img](https://mmbiz.qpic.cn/mmbiz_jpg/D67peceibeIRSoyibgdfYqrwFweWloZmY6obdia8LMCOcf7jYrqoOicbSibWDHjZ09bN0EvBBTP9mSvpbnJbWyQ7XkA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**2.2 优先级调度**

为每个进程分配一个优先级，按优先级进行调度。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**2.3 多级反馈队列**

一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

![img](https://mmbiz.qpic.cn/mmbiz_jpg/D67peceibeIRSoyibgdfYqrwFweWloZmY6Dv4ibTib5yHxPK32EQX36oDnA3QslaKm7nbKvnA1CNzMIgo14qbqCwxA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

# 死锁

## 必要条件

![img](https://mmbiz.qpic.cn/mmbiz_jpg/D67peceibeIRSoyibgdfYqrwFweWloZmY6qoibkMTUZmp6K7icPKTeHTn4selykhhBriclnIuM4viaVy8DxWbvUhBJkQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。
- 占有和等待：已经得到了某个资源的进程可以再请求新的资源。
- 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

**预防死锁：**

**资源一次性分配：**（破坏请求和保持条件）

**可剥夺资源：**即当某进程新的资源未满足时，释放已占有的资源（破坏不可剥夺条件）

**资源有序分配法：**系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）

 

**避免死锁:**

预防死锁的几种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从而获得 较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而，系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入[不安全状态](http://metc.gdut.edu.cn/os/oscai/chapter2/pages/ch29.htm#概念)，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银行家算法。

 

**检测死锁**

首先为每个进程和每个资源指定一个唯一的号码；

然后建立资源分配表和进程等待表，例如：

 

**解除死锁:**

当发现有进程死锁后，便应立即把它从死锁状态中解脱出来，常采用的方法有：

**剥夺资源：**从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态；

**撤消进程：**可以直接撤消死锁进程或撤消代价最小的进程，直至有足够的资源可用，死锁状态.消除为止；所谓代价是指优先级、运行代价、进程的重要性和价值等。

 

# 内存管理

算机硬件一直在飞速发展，内存容量也在不断增长，但是仍然不可能将所有用户进程和系统所需要的全部程序和数据放入主存中，所以操作系统必须将内存空间进行合理地划分和有效地动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。

## 操作系统中的虚拟内存

### 为什么需要虚拟内存

CPU 对内存的寻址最简单的方式就是直接使用物理内存地址，这种方式一般叫做物理寻址。早期的 PC 使用物理寻址，而且像数字信号处理器、嵌入式微控制器也使用物理寻址。物理寻址的好处是简单，坏处也有很多，比如：

**不安全**：操作系统的地址直接暴露给用户程序，用户程序可以破坏操作系统。这种解决方案是采用特殊的硬件保护。

**同时运行多个程序比较困难**：多个用户程序如果都直接引用物理地址，很容易互相干扰。那么是不是可以通过不断交换物理内存和磁盘来保证物理内存某一时间自由一个程序在运行呢？当时是可以的，但是这引入很多不必要和复杂的工作。

**用户程序大小受限**：受制于物理内存大小。我们现在的错觉是应用程序大小都小于物理内存，这主要是因为现在 PC 的物理内存都比较大。实际上只有 1G 物理内存的 PC 是可以运行 2G 的应用程序的。



虚拟内存的基本思想是：每个程序拥有独立的地址空间（也就是虚拟内存地址，或者称作虚拟地址），互不干扰。地址空间被分割成多个块，每一块称作一页（page），每一页有连续的地址范围。虚拟地址的页被映射到物理内存（通过 MMU，Memory Management Unit），但是并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将确实的部分装入物理内存。





虚拟内存为每个进程提供了一个大的，一直的和私有的地址空间。

1. 将主存看成一个存储在磁盘上的地址空间的缓存，在主存中只保存活动区域，并根据需要在磁盘和主存间传递数据。高效的利用了缓存。
2. 为每个进程提供了一致的地址空间，从而简化了内存管理
3. 保护每个进程的地址空间不被其他进程破坏。

## 分页式内存管理

页（page）
  一定大小字节数内存单元，属于逻辑单元。进程中所有代码、数据等信息均按页进行存储，属于逻辑组织形式。每个页有页码及其他信息。

页框(page frame)
  对应页字节数的物理内存，属于物理单元，是实际存在于物理内存中的可用地址单元。页框相当于页的容器，进程运行过程中，可能会动态加载不同页进入页框，CPU则直接对页框进行存取。  

页表（page table）
  既然有页和对应页框，那就必须有映射表将两者联系起来，而页表就是页和页框之间的映射表。换言之，知道页就可以查询到页框，知道页框，也可以查询到对应页。



##  分段

前面介绍了分页内存管理，可以说通过多级页表，TLB 等，分页内存管理方法已经相当不错了。那么分页有什么缺点呢？

1. **共享困难**：通过共享页面来实现共享当然是可以的。这里的问题在于我们要保证页面上只包含可以共享的内容并不是一件容易的事儿，因为进程空间是直接映射到页面上的。这样**一个页面上很可能包含不能共享的内容**（比如既包含代码又包含数据，代码可以共享，而数据不能共享）。
2. **程序地址空间受限于虚拟地址**：我们将程序全部映射到一个统一的虚拟地址的问题在于不好扩张。不如我们程序的地址按先代码放在一起，然后把数据放在一起，然后再放 XXX，这样其中某一部分的空间扩张起来都会影响到相邻的空间，非常不方便。

上面的问题一个比较直观的解决方法是提供多个独立的地址空间，也就是段（segment）。每个段的长度视具体的段不同而不同，而且是可以在运行期动态改变的。因为每个段都构成了一个独立的地址空间，所以它们可以独立的增长或者减小而不会影响到其他的段。如果一个段比较大，把它整个保存到内存中可能很不方便甚至是不可能的，因此可以对段采用分页管理，只有那些真正需要的页面才会被调入内存。

采用分段和分页结合的方式管理内存，一个地址由两个部分组成：段和段内地址。段内地址又进一步分为页号和页偏移。在进行内存访问时，过程如下：

1. 根据段号找到段描述符（存放段基址）。
2. 检查该段的页表是否在内存中。如果在，则找到它的位置，如果不在，则产生段错误。
3. 检查所请求的虚拟页面的页表项，如果该页面不在内存中则产生缺页中断，如果在内存中就从页表项中取出这个页面在内存中的起始地址。
4. 将页面起始地址和偏移量进行拼接得到物理地址，然后完成读写。

分段技术将计算机内存分解为各段，每个段有起始地址和长度，以及一系列权限信息（如读、写、执行等）。而同样地，将进程代码数据等为几个段，逻辑地址同样由段号和偏移量组成。



## **分页与分段的主要区别**

分页和分段有许多相似之处,比如两者都不要求作业连续存放.但在概念上两者完全不同,主要表现在以下几个方面:

(1)页是信息的物理单位,分页是为了实现非连续分配,以便解决内存碎片问题,或者说分页是由于系统管理的需要.段是信息的逻辑单位,它含有一组意义相对完整的信息,分段的目的是为了更好地实现共享,满足用户的需要.

(2)页的大小固定,由系统确定,将逻辑地址划分为页号和页内地址是由机器硬件实现的.而段的长度却不固定,决定于用户所编写的程序,通常由编译程序在对源程序进行编译时根据信息的性质来划分.

(3)分页的作业地址空间是一维的.分段的地址空间是二维的.

**段页式存储管理**

**1．基本思想：**

分页系统能有效地提高内存的利用率，而分段系统能反映程序的逻辑结构，便于段的共享与保护，将分页与分段两种存储方式结合起来，就形成了段页式存储管理方式。

在段页式存储管理系统中，作业的地址空间首先被分成若干个逻辑分段，每段都有自己的段号，然后再将每段分成若干个大小相等的页。对于主存空间也分成大小相等的页，主存的分配以页为单位。

段页式系统中，作业的地址结构包含三部分的内容：段号      页号       页内位移量

程序员按照分段系统的地址结构将地址分为段号与段内位移量，地址变换机构将段内位移量分解为页号和页内位移量。

为实现段页式存储管理，系统应为每个进程设置一个段表，包括每段的段号，该段的页表始址和页表长度。每个段有自己的页表，记录段中的每一页的页号和存放在主存中的物理块号。







## 页面置换算法

当发生缺页中断时，操作系统必须在内存中选择一个页面将其换出内存，以便为即将调入的页面腾出空间。

### 1. 最优页面置换算法

指淘汰以后永远不再被访问，或许是在未来最长时间内不再被访问的页面。

最佳置换算法通常可保证获得最低的缺页率。但由于无法预知一个进程的哪一页面是未来最长时间内不再被访问的，因而该算法无法实现，但可以利用该算法评价其它算法。

### 2. 最近未使用页面置换算法

### 3. 先进先出页面置换算法

指每次淘汰最早进入内存的页面。

方式为：操作系统维护一个所有当前在内存中的页面的链表，最新进入的页面放在表尾，最久进入的页面放在表头。当发生缺页中断时，淘汰表头的页面并把新调入的页面加到表尾。

### 4. 时钟页面置换算法

操作系统维护一个所有当前在内存中的页面的**环形链表**，表针指向最老的页面。当发生缺页中断时，算法首先检查表针指向的页面，如果该页的R位为0则淘汰该页面，并把新页面插入当前位置，然后把表针前移一个位置。如果R位为1就清除R位并把表针前移一个位置。重复这个过程直到找到一个R位为0的页面。

### 5. 最近最少未使用算法

指在前面几条指令中频繁使用的页面很可能在后面的几条指令中被使用。反过来说，已经很久没有使用的页面很可能在未来较长的一段时间内仍然不会被使用。当发生缺页中断时，淘汰未使用时间最长的页面。





