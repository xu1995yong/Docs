## Mysql数据库引擎比较

1. InnoDB存储引擎：InnoDB是默认的MySQL引擎，适用于OLTP的数据库应用。InnoDB存储引擎支持事务，采用行锁设计、支持外键约束、并提供非锁定读。InnoDB引擎使用多版本并发控制来获得高并发性，并且实现了SQL标准的4种隔离级别，默认为REPEATABLE级别。同时使用next-key locking的策略来避免幻读。
2. MyISAM存储引擎：主要面向OLAP的数据库应用。它提供高速存储和检索，以及全文搜索的能力。不支持事务，采用表锁设计，不支持外键。

## 业务层面的锁

### 乐观锁
**原理**：乐观锁认为数据一般情况下不会造成冲突，所以不会对数据提前加锁，而是在提交数据更新的时候，才对冲突进行检测。
**实现机制**：实现乐观锁有两种方式：

1. 使用版本号或者时间戳：数据版本是为数据增加的一个版本标识。当读取数据时，将版本标识的值一同读出，数据每更新一次，同时对版本标识进行更新。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的版本标识进行比对，如果标识值相等则予以更新，否则不更新数据。
2. 使用条件限制实现：适用于库存模型。

### 悲观锁
即在操作数据前，都要先获取该数据的锁。
**实现机制**：采用可重复读的事务隔离级别。

### 两者间的比较
乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。

## INNODB中的锁
### 1.行级锁及其3种实现
InnoDB实现了两种标准的行级锁：

- 共享锁：允许事务读一行数据，加锁方式：SELECT ... LOCK IN SHARE MODE
- 排他锁：允许事务删除或更新一行数据。通常对于UPDATE或者DELETE操作，或者SELECT … FOR UPDATE操作，都会对记录加排他锁。

如果一个事务持有了一个共享锁，其他事务仍然可以获取这行记录的共享锁，但不能获取到这行记录的排它锁。当一个事务获取到了某一行的排它锁，则其他事务将无法再获取这行记录的共享锁和排它锁。

**InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则InnoDB将使用表锁。**

**行锁的3种实现**

InnoDB存储引擎有3种行锁的算法：

- Record Lock：单个行记录上的锁。
- Gap Lock：间隙锁，锁定一个范围，但不包含记录本身。
- Next-Key Lock：等价于Record Lock + Gap Lock，锁定一个范围并锁定记录本身。Next-Key Lock解决了幻读问题。

### 2. 意向锁
InnoDB支持多粒度锁定，这种锁定允许事务在行级上的锁和表级上的锁共存。为了支持在不同粒度上进行加锁操作，InnoDB提供了两种意向锁：

- 意向排它锁（简称 IX 锁）表明一个事务意图在某个表中设置某些行的 x 锁
- 意向共享锁（简称 IS 锁）表明一个事务意图在某个表中设置某些行的 s 锁

意向锁的原则如下：

- 一个事务必须先持有该表上的 IS 或者更强的锁才能持有该表中某行的 S 锁
- 一个事务必须先持有该表上的 IX 锁才能持有该表中某行的 X 锁

这样根据锁的兼容矩阵，就避免了行级锁与表级锁间的冲突。

意向锁主要是解决不同粒度下的两类锁（表锁、行锁）互相阻塞的问题，考虑这个场景：
事务A锁住了表中的一行，让这一行只能读不能写。之后，事务B申请整个表的写锁。这个时候要阻塞B的操作，否则B会修改A读取的记录，导致A的锁失效。那如何判断当前是否需要阻塞B的操作呢？

1. 判断表是否已被其他事务用表锁锁表。

2. 判断表中的每一行是否已被行锁锁住。

这样的话就需要遍历整张表了，效率极其低下。为了提高效率，就有了意向锁。在意向锁存在的情况下，事务A必须先申请表的意向共享锁，成功后再申请一行的行锁。这样在判断时，步骤就变成了：
1. 判断表是否已被其他事务用表锁锁表
2. 发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。

### 3. 表级锁

表级锁是 MySQL 中锁定粒度最大的一种锁，表示对当前操作的整张表加锁。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。


## INNODB中的MVCC

MVCC（多版本并发控制）是一种提高数据库并发性的技术。它提供了一致性非锁定读，来避免事务间读写操作的阻塞。

一致性非锁定读：即如果读取的行正在执行delete或者update操作，则读取操作不等待锁的释放，而是读该行的一个快照数据，即事务的undo日志中记录的该行数据的之前版本。

MVCC只适用于READ COMMITTED和REPEATABLE READ事务隔离级别中，且在不同的事务隔离级别下对快照数据的定义不同：

- 在READ COMMITTED事务隔离级别下，快照数据是指被锁定行的最新版本数据。
- 在REPEATABLE READ事务隔离级别下，快照数据是指事务开始时的数据版本。



## 事务

**数据库事务**（简称：**事务**）是[数据库管理系统](https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F)执行过程中的一个逻辑单位。

### 事务的ACID特性

1. A(Atomicity)原子性：事务必须是原子工作单元；对于其数据修改，要么全都执行，要么全都不执行。

2. C(Consistency)一致性：指事务必须始终保持系统处于一致的状态。比如银行转帐事务，不管事务成功还是失败，应该保证事务结束后两个人的存款总额前后一致。

3. I(Isolation)隔离性：并发执行的多个事务间相互隔离。即一个事务内部操作及使用的数据对其他事务隔离。其他事务不能读取本事务数据的中间结果。

4. D(Durability)持久性：即事务成功结束后，对数据库的更新就必须永久保存下来。即使系统崩溃，数据库还能恢复到事务成功结束时的状态

### 事务ACID特性的保证

- 如何保证原子性：实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的sql语句。InnoDB实现回滚，靠的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。
- 如何保证持久性：redo log被引入来解决这个问题。更为精确的讲，redo log是WAL机制的，不是因为redo log解决了一致性问题，而是redo log采用的是WAL（Write-ahead logging，预写式日志）解决了一致性问题。，、所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。
- 如何保证隔离性：InnoDB通过锁机制来保证这一点。锁机制的基本原理可以概括为：事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据；该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁。
- 如何保证一致性：前面提到的原子性、持久性和隔离性，都是为了实现数据库状态的一致性的基础。在此基础上，数据库层面提供了事务的开启、提交、回滚操作，保证了一致性。此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。

### 事务并发带来的问题

1. 脏读：当前事务可以读到另一事务修改但尚未提交的数据。脏读违反了事务的隔离性。

   ![img](https://upload-images.jianshu.io/upload_images/5879294-6424e361ec6ae52e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)

2. 不可重复读：在事务执行过程中，由于其他事务修改了数据，导致当前事务前后两次SELECT返回的结果集中记录的值不同。不可重复读违反了事务的一致性。

   ![img](https://upload-images.jianshu.io/upload_images/5879294-a5aa7d5671f3b770.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)

3. 幻读：在事务执行过程中，由于其他事务增加或删除了数据，导致当前事务前后两次SELECT返回的结果集中记录的数量不同。

   ![img](https://upload-images.jianshu.io/upload_images/5879294-2d4b770f4afd4871.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)
   
   **在Repeatable Read隔离级别下，InnoDB引擎采用Next-Key Lock来解决幻读现象**
举例说明如何解决：
>   例如：CREATE TABLE T (a int primary key)，表T中由1，2，5这三个值组成。
>   若这时事务T1执行select * from t where a > 2 for update;该操作应该返回5这个结果，但如果此时另一个事务T2插入了4这个值，那事务T1再次执行上述的SQL会得到4和5，这样就产生了幻影现象。
>   当InnoDB引擎采用Next-Key Lock算法时，对于语句select * from t where a > 2 for update，其锁住的不只是5这单个值，而是对（2，+∞）这个范围加了X锁。这样对于这个范围的插入都是不被允许的，从而避免了幻影现象。

4. 丢失修改：一个事务的更新操作会被另一个事务的更新操作覆盖。在当前数据库的任何隔离级别下，都不会导致数据库理论意义上的丢失修改，因为对数据的修改操作都会加X锁。但是在实际应用中还有另一个逻辑意义的丢失修改问题：
   - 事务A查询一行数据，放入本地内存，并显示给一个终端用户UserA。

   - 事务B也查询该行数据，并将取得的数据显示给终端用户UserB。

   - UserA修改这行记录，更新数据库并提交。

   - UserB修改这行记录，更新数据库并提交。

     要避免丢失更新的发生，有两种方式：

     1. 悲观锁方式：为每个SELECT操作都加上排他锁（FOR UPDATE）。这样事务B就必须等待事务A完成后才能继续。
     2. 乐观锁方式：
### 事务的隔离级别及实现原理

为了解决事务并发带来的问题，数据库设计了四种隔离级别：

1. 读未提交(Read Uncommitted)：会读取到其他事务中未提交的数据，即脏读。

   - 实现原理：事务对读取操作不加锁；事务对更新操作加共享锁，事务结束才释放。
2. 读已提交(Read Committed)：只能读取到其他事务已经提交的数据。解决了脏读问题，存在不可重复读的问题。

   - 实现原理：事务对读取操作采用MVCC；事务对更新操作加独占锁，事务结束才释放。
3. 可重复读(Repeated Read)：在同一个事务内的所有查询操作都与事务开始的时刻一致。可重复读是InnoDB默认级别。解决了不可重复读，但还存在幻象读。InnoDB中采用next-key lock解决了幻读。

   - 实现原理：事务对读取操作采用MVCC；事务对更新操作加独占锁，事务结束才释放。
4. 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。
   - 实现原理：

#### 隔离级别的选择

一般选择**读已提交**。

1. **在可重复读隔离级别下，存在间隙锁，导致出现死锁的几率比RC大的多**
2. **在可重复读隔离级别下，条件列未命中索引会锁表！而在RC隔离级别下，只锁行**
3. **在读已提交隔离级别下，半一致性读(semi-consistent)特性增加了update操作的并发性**

## MySQL中的索引

### 为什么需要索引

索引是典型的通过空间换时间的解决方案。假如没有索引的话，用户如果想要查找某个数据，则需要从磁盘中将所有的数据全部读取到内存中，在根据用户的设定条件来查找数据。但是这些数据在物理磁盘中不一定是顺序存储，或者内存无法加载过多的数据，这样会导致需要进行多次磁盘IO，才能完成整个条件查询。
众所周知磁盘IO相对于其他操作是非常费时，因此如何减少磁盘IO次数成为了提高查询的关键。基本方法有两种：

1. 减少数据占用的磁盘空间。比如压缩算法、优化数据存储结构。
2. 减少访问数据的总量。在读出或写入的数据中，有一部分是数据操作所必须的，这部分称作有效数据。剩余的部分则不是数据操作必须的数据，称为无效数据。因此我们要努力减少无效数据的访问。

通过键(KEY)来访问数据可以较好的解决这个问题。假设一条数据(数据库的一行数据)长度有100字节，而我们只使用10字节的数据作为键，那么通过读取10字节就可以直接定位100字节的原始数据。这样可以起到减少读入的数据量来达到相同的查找数据的效果。
但是这样做法额外消耗就是我们需要将这10字节的数据重新组合并进行存储，这就是索引文件。通过在索引文件中查找到需要的数据后，就可以通过指针来定位原始数据。

### Mysql中索引的组织方式

#### 为什么使用B+树

常见的索引组织方式，包括Hash表、树型结构（比如：平衡二叉树、红黑树、B树、B+树），那为什么Mysql中采用B+树的方式保存索引呢？

#### Hash索引的缺陷

1. Hash 索引**仅仅能满足等值查询，不能使用范围查询**。由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。
2. Hash 索引无法被用来避免数据的排序操作。由于 **Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样**，所以数据库**无法利用索引的数据来避免任何排序**运算；
3. Hash 索引**不支持多列联合索引的最左匹配规则**；对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。
4. 由于Hash冲突问题，**大量重复键值情况下**，哈希索引的效率也是极低的。



### B树

B树是一种多叉平衡树。它是为磁盘设计的一种平衡查找树。一棵m阶的B树需满足以下条件：

1. 树中每个结点最多含有m个子树（m>=2）；
2. 除根结点和叶子结点外，其它每个结点至少有[ceil(m / 2)]个子树（向上取整：比自己大的最小整数）；
3. 若根结点不是叶子结点，则至少有2个子树
4. 所有叶子节点均在同一层、


![img](https://pic2.zhimg.com/80/v2-2c2264cc1c6c603dfeca4f84a2575901_hd.jpg)

### B+树
 B+树是B-树的变体，也是一种多路搜索树：

       1.其定义基本与B-树同，除了：
    
       2.非叶子结点的子树指针与关键字个数相同；
    
       3.非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树

（B-树是开区间）；

       5.为所有叶子结点增加一个链指针；
    
       6.所有关键字都在叶子结点出现；
B+树是针对文件系统产生的一种B树的变形。与B树相比，具有如下特点：

1. 磁盘读写代价更低：所有的非叶子节点仅包含索引信息。这样在一个磁盘的盘块中能容纳的非叶子节点数更多，在读入内存时一次读取的有效信息更多，IO次数就会相应减少。
2. 叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小以双向链表的形式顺序链接。
3. 查询效率更加稳定：由于非叶子结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。而B+树又是平衡树，导致每一个数据的查询效率相当。

### 为什么使用B+树

MySQL 是基于磁盘的数据库系统，索引往往以索引文件的形式存储的磁盘上，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。为什么使用B-/+Tree，还跟磁盘存取原理有关。

### 局部性原理与磁盘预读

由于磁盘的存取速度与内存之间鸿沟,为了提高效率,要尽量减少磁盘I/O.磁盘往往不是严格按需读取，而是每次都会预读,磁盘读取完需要的数据,会顺序向后读一定长度的数据放入内存。而这样做的理论依据是计算机科学中著名的局部性原理：
当一个数据被用到时，其附近的数据也通常会马上被使用，程序运行期间所需要的数据通常比较集中


由于磁盘顺序读取的效率很高(不需要寻道时间，只需很少的旋转时间)，因此对于具有局部性的程序来说，预读可以提高I/O效率.预读的长度一般为页(page)的整倍数。
在加上B+树出度较大，整个树扁平。逻辑上相近的节点，在物理磁盘上也相近。能最大化利用局部性原理。尽量减少IO次数。

```
MySQL(默认使用InnoDB引擎),将记录按照页的方式进行管理,每页大小默认为16K(这个值可以修改).linux 默认页大小为4K
```

### 聚簇索引

数据库中的B+索引可以分为**聚簇索引**和**辅助索引**。

InnoDB存储引擎表是索引组织表，表中数据按照主键顺序存放。

聚簇索引就是按照每张表的主键构造一棵B+树，叶子节点中存放表的行记录数据，叶子节点间通过双向链表进行链接。每张表只能拥有一个聚簇索引。

聚簇索引由数据库自动生成。

如果没有主键，则按照下列规则来建聚簇索引

- 没有主键时，会用一个唯一且不为空的索引列做为主键，成为此表的聚簇索引
- 如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。



### 辅助索引

辅助索引中，叶子节点并不包含行记录的全部数据。叶子节点除了包含键值，还包含了指向该辅助索引相对应的行数据的主键索引的指针。这样，当通过辅助索引寻找数据时，InnoDB引擎会遍历辅助索引并通过该指针获得一个完整的行记录。每张表上可以有多个辅助索引。



### 建立索引的原则

1. 定义主键的数据列一定要建立索引。
2. 定义有外键的数据列一定要建立索引。
3. 对于经常查询的数据列最好建立索引。
4. 对于需要在指定范围内的快速或频繁查询的数据列;
5. 经常用在WHERE子句中的数据列。
6. 经常出现在关键字order by、group by、distinct后面的字段，建立索引。如果建立的是复合索引，索引的字段顺序要和这些关键字后面的字段顺序一致，否则索引不会被使用。
7. 对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。
8. 对于定义为text、image和bit的数据类型的列不要建立索引。
9. 对于经常存取的列避免建立索引 
10. 限制表上的索引数目。对一个存在大量更新操作的表，所建索引的数目一般不要超过3个，最多不要超过5个。索引虽说提高了访问速度，但太多索引会影响数据的更新操作。
11. 对复合索引，按照字段在查询条件中出现的频度建立索引。在复合索引中，记录首先按照第一个字段排序。对于在第一个字段上取值相同的记录，系统再按照第二个字段的取值排序，以此类推。因此只有复合索引的第一个字段出现在查询条件中，该索引才可能被使用,因此将应用频度高的字段，放置在复合索引的前面，会使系统最大可能地使用此索引，发挥索引的作用。



### 索引优化原则

1. 索引覆盖 全值匹配
2. 最左匹配原则
3. 在索引列上做任何计算，或者使用函数、类型转换操作，都会导致索引失效而转向全表扫描。
4. 索引上使用了大于、小于等范围比较后，索引右边的列上的索引将失效。
5. 尽量使用覆盖索引，即使查询列表与索引列一致。尽量少使用select *
6. 对索引列上使用不等于操作（!= 或 <>）无法使用索引
7. 对索引列上使用is null, is not null操作也无法使用索引
8. like操作如果以%开头，将使索引失效而转向全表扫描。除非要查询的列覆盖索引
9. 字符串不加单引号时，索引会失效
10. or操作会使索引失效

## **最左前缀匹配原则**

在mysql建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，



## 分库分表

### 垂直切分

垂直切分常见有**垂直分库**和**垂直分表**两种。

#### 垂直分库

**垂直分库**就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。

#### 垂直分表

**垂直分表**是基于数据库中的表字段来进行的。业务中可能存在一些字段比较多的表，表中某些字段长度较大。这些长字段我们又只是偶尔需要用到。这时候我们就可以考虑将表进行垂直拆分了。将某些不常用的，但是长度又很大的字段拎出来放到另外一张表。

MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。另外数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。

### 垂直切分优缺点

优点：

1. 不同系统可以使用不同的库表，解决业务系统层面的耦合，业务清晰
2. 高并发场景下，垂直切分一定程度地提升IO、数据库连接数，缓解单机硬件资源的瓶颈

缺点：

1. 部分查询需要在业务代码逻辑里面做聚合，增加开发复杂度
2. 事务处理复杂，可能需要在业务代码层面做处理
3. 不能根本解决单表数据量过大的问题



## 水平切分

当业务难以更细粒度地进行垂直切分，或者切分后单表数据依然过大，存在单库读写、存储性能瓶颈时候，这时候就可以考虑水平切分了。

水平切分又可以分为**库内分表**和**分库分表**。是根据表内数据的内在逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。

### 库内分表

库内分表就是在同一个db上，将表按照某种条件拆分为多张表。

比如一张订单表，我们可以依据订单的日期，按月建表。一月份的订单放`month_201901`这张表，二月份的订单放`month_201902`这张表。

库内分表只解决单表数据量过大问题，但没有将表分布到不同机器上，所有请求还是在一台物理机上竞争cpu，内存，IO，对于减轻mysql负载压力来说帮助不大。

### 分库分表

分库分表就是将表不仅拆分，而且拆分到不同机器上。可以指定一张表的`shardKey`，然后对`shardKey`取hash，根据hash值将数据放到不同的数据库中。

这个可以解决单机物理资源的瓶颈问题。

### 分库分表优缺点

优点：

1. 不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力
2. 应用端改造较小，不需要拆分业务模块

缺点：

1. 跨分片的事务一致性较难保障，一般需要一层中间件，介于业务和db之间。对应腾讯云上的DCDB数据库所包含的Proxy层。
2. 跨库的join关联查询性能较差

### 分库分表带来的问题

分库分表能有效地缓解单机和单库带来的性能瓶颈和压力，突破网络IO、磁盘存储、CPU处理能力的瓶颈，同时也带来了一些问题。

1. 事务一致性问题

   当更新内容同时分布在不同库中，不可避免会带来跨库事务问题。跨分片事务也是分布式事务，没有简单的方案，一般可使用”XA协议”和”两阶段提交”处理。

   分布式事务能最大限度保证数据库操作的原子性。但在提交事务时需要协调多个节点，推后了提交事务的时间点，延长了事务的执行时间。导致事务在访问共享资源时发生冲突或死锁的概率增高。随着数据库节点的增多，这种趋势会越来越严重，从而成为系统在数据库层面上水平扩展的枷锁。

2. 跨节点关联查询 join 问题

   切分之前，系统中很多列表和详情页所需的数据可以通过sql join来完成。而切分之后，数据可能分布在不同的节点上，此时join带来的问题就比较麻烦了，考虑到性能，尽量避免使用join查询。

   解决这个问题的一些方法：

   - **全局表**：

     全局表，也可看做是”数据字典表”，就是系统中所有模块都可能依赖的一些表，为了避免跨库join查询，可以将这类表在每个数据库中都保存一份。这些数据通常很少会进行修改，所以也不担心一致性的问题。比如腾讯云上的DCDB，可以创建广播表，其实就是全局表。每个节点都有该表的全量数据，该表的所有操作都将广播到所有物理分片（set）中。

   - **字段冗余**

     一种典型的反范式设计，利用空间换时间，为了性能而避免join查询。例如：订单表保存userId时候，也将userName冗余保存一份，这样查询订单详情时就不需要再去查询”买家user表”了。

     但这种方法适用场景也有限，比较适用于依赖字段比较少的情况。而冗余字段的数据一致性也较难保证，就像上面订单表的例子，买家修改了userName后，是否需要在历史订单中同步更新呢？这也要结合实际业务场景进行考虑。

   - **数据组装**

     在系统层面，分两次查询，第一次查询的结果集中找出关联数据id，然后根据id发起第二次请求得到关联数据。最后将获得到的数据进行字段拼装。

     

     3. 全局主键避重问题

     在分库分表环境中，由于表中数据同时存在不同数据库中，主键平时使用的自增长将无用武之地，某个分区数据库自生成的ID无法保证全局唯一。因此需要单独设计全局主键，以避免跨库主键重复问题。有一些常见的主键生成策略。这里可以参阅[Leaf——美团点评分布式ID生成系统](https://tech.meituan.com/2017/04/21/mt-leaf.html)一文。





## MySQL中的日志

MySQL中的日志文件包括：重做日志、回滚日志、二进制日志、错误日志、慢查询日志、一般查询日志、中继日志。

### 事务日志

#### redo日志

redo日志记录事务执行后的状态，用来恢复未写入data file的，但事务已成功更新的数据，**保证事务的原子性、持久性**。尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo日志进行重做。redo日志是物理日志，记录物理页的修改。

#### undo日志

undo日志记录事务开始前的状态，用于事务失败时的回滚操作，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。**保证事务的一致性**。undo日志是逻辑日志，当回滚日志被使用时，它只会按照日志**逻辑地**将数据库中的修改撤销掉看，可以**理解**为，我们在事务中使用的每一条 `INSERT` 都对应了一条 `DELETE`，每一条 `UPDATE` 也都对应一条相反的 `UPDATE` 语句。

### 二进制日志

MySQL的二进制日志（binary log）是一个二进制文件，主要用于记录修改数据或有可能引起数据变更的MySQL语句。二进制日志（binary log）中记录了对MySQL数据库执行更改的所有操作，并且记录了语句发生时间、执行时长、操作数据等其它额外信息，但是它不记录SELECT、SHOW等那些不修改数据的SQL语句。二进制日志（binary log）主要用于数据库恢复和主从复制，以及审计（audit）操作。

binlog有三种格式：Statement、Row以及Mixed。

- 基于SQL语句的复制(statement-based replication,SBR)：记录sql语句在bin log中。优点是只需要记录会修改数据的sql语句到binlog中，减少了binlog日质量，节约I/O，提高性能。缺点是在某些情况下，会导致主从节点中数据不一致（比如sleep(),now()等）。而且有些数据更新语句，可能依赖其他因素。例如，同一条sql在主库和备库上执行的时间可能稍微或很不相同，因此在传输的binlog日志中，除了查询语句，还包括一些元数据信息，如当前的时间戳。即便如此，还存在着一些无法被正确复制的SQL，例如，使用CURRENT_USER()函数语句。存储过程和触发器在使用基于语句的复制模式时也可能存在问题。另外一个问题是更新必须是串行的。这需要更多的锁。并且不是所有的存储引擎都支持这种复制模式。
- 基于行的复制(row-based replication,RBR)：将SQL语句分解为基于Row更改的语句并记录在bin log中，也就是只记录哪条数据被修改了，修改成什么样。优点是不会出现某些特定情况下的存储过程、或者函数、或者trigger的调用或者触发无法被正确复制的问题。缺点是会产生大量的日志，尤其是修改table的时候会让日志暴增,
- 混合模式复制(mixed-based replication,MBR)：对于一般的复制使用STATEMENT模式保存到binlog，对于STATEMENT模式无法复制的操作则使用ROW模式来保存

MYSQL INNDODB的REDO LOG与BINLOG从表面上看来是非常相似的。然而本质上有很大的区别：

第一:REDO LOG是在INNODB存储引擎层产生，而BINLOG是MYSQL数据库的上层产生的，并且二进制日志不仅仅针对INNODB存储引擎，MYSQL数据库中的任何存储引擎对于数据库的更改都会产生二进制日志。

第二：两种日志记录的内容形式不同。MYSQL的BINLOG是逻辑日志，其记录是对应的SQL语句。而INNODB存储引擎层面的重做日志是物理日志。

第三：两种日志与记录写入磁盘的时间点不同，二进制日志只在事务提交完成后进行一次写入。而INNODB存储引擎的重做日志在事务进行中不断地被写入，并日志不是随事务提交的顺序进行写入的。

二进制日志仅在事务提交时记录，并且对于每一个事务，仅在事务提交时记录，并且对于每一个事务，仅包含对应事务的一个日志。而对于INNODB存储引擎的重做日志，由于其记录是物理操作日志，因此每个事务对应多个日志条目，并且事务的重做日志写入是并发的，并非在事务提交时写入，做其在文件中记录的顺序并非是事务开始的顺序。

### 二进制日志与重做日志的区别

二进制文件会记录所有与MySQL数据库相关的日志记录，包括其它各种各样的存储引擎，而重做日志只记录InnoDB相关的；二进制文件记录的是关于一个事务的具体操作内容，即该日志是逻辑日志（记录的是Insert、Update等操作记录），而重做日志记录的是关于每个页的更改的物理情况；二进制文件仅在事务提交前进行提交，即只写磁盘一次，不论这时候事务有多大，而在事务执行过程中，则不断有重做日志条目被写入到重做日志文件中。



## MySQL的主从复制

MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。MySQL 默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。
通过在主库上记录二进制日志（binlog）、在备库上重放日志的方式来实现异步的数据复制。这意味着、在同一时间点备库上的数据可能和主库不一致，并且无法保证主库备库之间的延迟。
### 异步复制过程
1.  Master将变更记录到二进制日志(binary log)中。
2.  从库发起连接，连接到主库，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。
3.  从库生成两个线程，一个I/O线程，一个SQL线程；I/O线程用来接收主库的binlog，并将得到的binlog日志写到relay log（中继日志） 文件中；SQL 线程，会读取relay log文件中的日志，并解析成具体操作，来实现主从的操作一致，而最终数据一致；

### 主从复制主要用途
**读写分离**

在开发工作中，有时候会遇见某个sql 语句需要锁表，导致暂时不能使用读的服务，这样就会影响现有业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作。

**数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换**

**高可用HA**

**架构扩展**

随着系统中业务访问量的增大，如果是单机部署数据库，就会导致I/O访问频率过高。有了主从复制，增加多个数据存储节点，将负载分布在多个从节点上，降低单机磁盘I/O访问的频率，提高单个机器的I/O性能。





## MySQL的读写分离

MySQL读写分离基本原理是让master数据库处理写操作，slave数据库处理读操作。master将写操作的变更同步到各个slave节点。**适用于读多写少的场景**。因为数据库压力如果是在写操作上，读写分离之后压力还是在主库上，和单机区别不大。

在单机的情况下，一般我们做数据库优化都会加索引，但是加了索引对查询有优化，但是会影响写入，因为写入数据会更新索引。所以做了**读写分离之后，我们可以单独的针对从库(读库)做索引上的优化，而主库(写库)可以减少索引而提高写的效率。**

关键业务读写都由主库承担，非关键业务读写分离

类似付钱的这种业务，读写都到主库，避免延迟的问题，但是例如改个头像啊，个人签名这种比较不重要的就读写分离，查询都去从库查，毕竟延迟一下影响也不大，不会立马打客服电话哈哈。/

#### 读写分离的挑战

1. **对sql类型进行判断**。如果是select等读请求，就走从库，如果是insert、update、delete等写请求，就走主库。

2. **主从数据同步延迟问题**。因为数据是从master节点通过网络同步给多个slave节点，因此必然存在延迟。因此有可能出现我们在master节点中已经插入了数据，但是从slave节点却读取不到的问题。对于一些强一致性的业务场景，要求插入后必须能读取到，因此对于这种情况，我们需要提供一种方式，让读请求也可以走主库，而主库上的数据必然是最新的。

3. **事务问题**。如果一个事务中同时包含了读请求(如select)和写请求(如insert)，如果读请求走从库，写请求走主库，由于跨了多个库，那么jdbc本地事务已经无法控制，属于分布式事务的范畴。而分布式事务非常复杂且效率较低。因此对于读写分离，目前主流的做法是，事务中的所有sql统一都走主库，由于只涉及到一个库，jdbc本地事务就可以搞定。

4. 高可用问题

   。主要包括：

   - **新增slave节点**：如果新增slave节点，应用应该感知到，可以将读请求转发到新的slave节点上。
   - **slave宕机或下线**：如果其中某个slave节点挂了/或者下线了，应该对其进行隔离，那么之后的读请求，应用将其转发到正常工作的slave节点上。
   - **master宕机**：需要进行主从切换，将其中某个slave提升为master，应用之后将写操作转到新的master节点上。





MySQL读写分离能提高系统性能的原因在于：

- 物理服务器增加，机器处理能力提升。拿硬件换性能。
- 主从只负责各自的读和写，极大程度缓解X锁和S锁争用。
- slave可以配置myiasm引擎，提升查询性能以及节约系统开销。
- master直接写是并发的，slave通过主库发送来的binlog恢复数据是异步。
- slave可以单独设置一些参数来提升其读的性能。
- 增加冗余，提高可用性。
- 

