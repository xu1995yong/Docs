## Mysql数据库引擎比较

1. InnoDB存储引擎：InnoDB是默认的MySQL引擎，适用于OLTP的数据库应用。InnoDB存储引擎支持事务，采用行锁设计、支持外键约束、并提供非锁定读。InnoDB引擎使用多版本并发控制来获得高并发性，并且实现了SQL标准的4种隔离级别，默认为REPEATABLE级别。同时使用next-key locking的策略来避免幻读。
2. MyISAM存储引擎：主要面向OLAP的数据库应用。它提供高速存储和检索，以及全文搜索的能力。不支持事务，采用表锁设计，不支持外键。

## 业务层面的锁

### 乐观锁
**原理**：乐观锁认为数据一般情况下不会造成冲突，所以不会对数据提前加锁，而是在提交数据更新的时候，才对冲突进行检测。
**实现机制**：实现乐观锁有两种方式：

1. 使用版本号或者时间戳：数据版本是为数据增加的一个版本标识。当读取数据时，将版本标识的值一同读出，数据每更新一次，同时对版本标识进行更新。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的版本标识进行比对，如果标识值相等则予以更新，否则不更新数据。
2. 使用条件限制实现：适用于库存模型。

### 悲观锁
即在操作数据前，都要先获取该数据的锁。
**实现机制**：采用可重复读的事务隔离级别。

### 两者间的比较
乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。

## INNODB中的锁
### 1.行级锁及其3种实现
InnoDB实现了两种标准的行级锁：

- 共享锁：允许事务读一行数据，加锁方式：SELECT ... LOCK IN SHARE MODE
- 排他锁：允许事务删除或更新一行数据。通常对于UPDATE或者DELETE操作，或者SELECT … FOR UPDATE操作，都会对记录加排他锁。

如果一个事务持有了一个共享锁，其他事务仍然可以获取这行记录的共享锁，但不能获取到这行记录的排它锁。当一个事务获取到了某一行的排它锁，则其他事务将无法再获取这行记录的共享锁和排它锁。

**InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则InnoDB将使用表锁。**

**行锁的3种实现**

InnoDB存储引擎有3种行锁的算法：

- Record Lock：单个行记录上的锁。
- Gap Lock：间隙锁，锁定一个范围，但不包含记录本身。
- Next-Key Lock：等价于Record Lock + Gap Lock，锁定一个范围并锁定记录本身。Next-Key Lock解决了幻读问题。

### 2. 意向锁
InnoDB支持多粒度锁定，这种锁定允许事务在行级上的锁和表级上的锁共存。为了支持在不同粒度上进行加锁操作，InnoDB提供了两种意向锁：

- 意向排它锁（简称 IX 锁）表明一个事务意图在某个表中设置某些行的 x 锁
- 意向共享锁（简称 IS 锁）表明一个事务意图在某个表中设置某些行的 s 锁

意向锁的原则如下：

- 一个事务必须先持有该表上的 IS 或者更强的锁才能持有该表中某行的 S 锁
- 一个事务必须先持有该表上的 IX 锁才能持有该表中某行的 X 锁

这样根据锁的兼容矩阵，就避免了行级锁与表级锁间的冲突。

意向锁主要是解决不同粒度下的两类锁（表锁、行锁）互相阻塞的问题，考虑这个场景：
事务A锁住了表中的一行，让这一行只能读不能写。之后，事务B申请整个表的写锁。这个时候要阻塞B的操作，否则B会修改A读取的记录，导致A的锁失效。那如何判断当前是否需要阻塞B的操作呢？

1. 判断表是否已被其他事务用表锁锁表。

2. 判断表中的每一行是否已被行锁锁住。

这样的话就需要遍历整张表了，效率极其低下。为了提高效率，就有了意向锁。在意向锁存在的情况下，事务A必须先申请表的意向共享锁，成功后再申请一行的行锁。这样在判断时，步骤就变成了：
1. 判断表是否已被其他事务用表锁锁表
2. 发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。

### 3. 表级锁

表级锁是 MySQL 中锁定粒度最大的一种锁，表示对当前操作的整张表加锁。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。


## INNODB中的MVCC

MVCC（多版本并发控制）是一种提高数据库并发性的技术。它提供了一致性非锁定读，来避免事务间读写操作的阻塞。

一致性非锁定读：即如果读取的行正在执行delete或者update操作，则读取操作不等待锁的释放，而是读该行的一个快照数据，即事务的undo日志中记录的该行数据的之前版本。

MVCC只适用于READ COMMITTED和REPEATABLE READ事务隔离级别中，且在不同的事务隔离级别下对快照数据的定义不同：

- 在READ COMMITTED事务隔离级别下，快照数据是指被锁定行的最新版本数据。
- 在REPEATABLE READ事务隔离级别下，快照数据是指事务开始时的数据版本。



## 事务

**数据库事务**（简称：**事务**）是[数据库管理系统](https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F)执行过程中的一个逻辑单位。

### 事务的ACID特性

1. A(Atomicity)原子性：事务必须是原子工作单元；对于其数据修改，要么全都执行，要么全都不执行。

2. C(Consistency)一致性：指事务必须始终保持系统处于一致的状态。比如银行转帐事务，不管事务成功还是失败，应该保证事务结束后两个人的存款总额前后一致。

3. I(Isolation)隔离性：并发执行的多个事务间相互隔离。即一个事务内部操作及使用的数据对其他事务隔离。其他事务不能读取本事务数据的中间结果。

4. D(Durability)持久性：即事务成功结束后，对数据库的更新就必须永久保存下来。即使系统崩溃，数据库还能恢复到事务成功结束时的状态

### 事务ACID特性的保证

- 如何保证原子性：实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的sql语句。InnoDB实现回滚，靠的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。
- 如何保证持久性：redo log被引入来解决这个问题。更为精确的讲，redo log是WAL机制的，不是因为redo log解决了一致性问题，而是redo log采用的是WAL（Write-ahead logging，预写式日志）解决了一致性问题。，、所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。
- 如何保证隔离性：InnoDB通过锁机制来保证这一点。锁机制的基本原理可以概括为：事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据；该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁。
- 如何保证一致性：前面提到的原子性、持久性和隔离性，都是为了实现数据库状态的一致性的基础。在此基础上，数据库层面提供了事务的开启、提交、回滚操作，保证了一致性。此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。

### 事务并发带来的问题

1. 脏读：当前事务可以读到另一事务修改但尚未提交的数据。脏读违反了事务的隔离性。

   ![img](https://upload-images.jianshu.io/upload_images/5879294-6424e361ec6ae52e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)

2. 不可重复读：在事务执行过程中，由于其他事务修改了数据，导致当前事务前后两次SELECT返回的结果集中记录的值不同。不可重复读违反了事务的一致性。

   ![img](https://upload-images.jianshu.io/upload_images/5879294-a5aa7d5671f3b770.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)

3. 幻读：在事务执行过程中，由于其他事务增加或删除了数据，导致当前事务前后两次SELECT返回的结果集中记录的数量不同。

   ![img](https://upload-images.jianshu.io/upload_images/5879294-2d4b770f4afd4871.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)
   
   **在Repeatable Read隔离级别下，InnoDB引擎采用Next-Key Lock来解决幻读现象**
举例说明如何解决：
>   例如：CREATE TABLE T (a int primary key)，表T中由1，2，5这三个值组成。
>   若这时事务T1执行select * from t where a > 2 for update;该操作应该返回5这个结果，但如果此时另一个事务T2插入了4这个值，那事务T1再次执行上述的SQL会得到4和5，这样就产生了幻影现象。
>   当InnoDB引擎采用Next-Key Lock算法时，对于语句select * from t where a > 2 for update，其锁住的不只是5这单个值，而是对（2，+∞）这个范围加了X锁。这样对于这个范围的插入都是不被允许的，从而避免了幻影现象。

4. 丢失修改：一个事务的更新操作会被另一个事务的更新操作覆盖。在当前数据库的任何隔离级别下，都不会导致数据库理论意义上的丢失修改，因为对数据的修改操作都会加X锁。但是在实际应用中还有另一个逻辑意义的丢失修改问题：
   - 事务A查询一行数据，放入本地内存，并显示给一个终端用户UserA。

   - 事务B也查询该行数据，并将取得的数据显示给终端用户UserB。

   - UserA修改这行记录，更新数据库并提交。

   - UserB修改这行记录，更新数据库并提交。

     要避免丢失更新的发生，有两种方式：

     1. 悲观锁方式：为每个SELECT操作都加上排他锁（FOR UPDATE）。这样事务B就必须等待事务A完成后才能继续。
     2. 乐观锁方式：
### 事务的隔离级别及实现原理

为了解决事务并发带来的问题，数据库设计了四种隔离级别：

1. 读未提交(Read Uncommitted)：会读取到其他事务中未提交的数据，即脏读。

   - 实现原理：事务对读取操作不加锁；事务对更新操作加共享锁，事务结束才释放。
2. 读已提交(Read Committed)：只能读取到其他事务已经提交的数据。解决了脏读问题，存在不可重复读的问题。

   - 实现原理：事务对读取操作采用MVCC；事务对更新操作加独占锁，事务结束才释放。
3. 可重复读(Repeated Read)：在同一个事务内的所有查询操作都与事务开始的时刻一致。可重复读是InnoDB默认级别。解决了不可重复读，但还存在幻象读。InnoDB中采用next-key lock解决了幻读。

   - 实现原理：事务对读取操作采用MVCC；事务对更新操作加独占锁，事务结束才释放。
4. 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。
   - 实现原理：

#### 隔离级别的选择

一般选择**读已提交**。

1. **在可重复读隔离级别下，存在间隙锁，导致出现死锁的几率比RC大的多**
2. **在可重复读隔离级别下，条件列未命中索引会锁表！而在RC隔离级别下，只锁行**
3. **在读已提交隔离级别下，半一致性读(semi-consistent)特性增加了update操作的并发性**

## 索引

### B树

B树是一种多叉平衡树。它是为磁盘设计的一种平衡查找树。一棵m阶的B树需满足以下条件：

1. 树中每个结点最多含有m个子树（m>=2）；
2. 除根结点和叶子结点外，其它每个结点至少有[ceil(m / 2)]个子树（向上取整：比自己大的最小整数）；
3. 若根结点不是叶子结点，则至少有2个子树
4. 所有叶子节点均在同一层、


![img](https://pic2.zhimg.com/80/v2-2c2264cc1c6c603dfeca4f84a2575901_hd.jpg)

### B+树

B+树是针对文件系统产生的一种B树的变形。与B树相比，具有如下特点：

1. 磁盘读写代价更低：所有的非叶子节点仅包含索引信息。这样在一个磁盘的盘块中能容纳的非叶子节点数更多，在读入内存时一次读取的有效信息更多，IO次数就会相应减少。
2. 叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小以双向链表的形式顺序链接。
3. 查询效率更加稳定：由于非叶子结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。而B+树又是平衡树，导致每一个数据的查询效率相当。

### 为什么使用B+树

红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构。MySQL 是基于磁盘的数据库系统,索引往往以索引文件的形式存储的磁盘上,索引查找过程中就要产生磁盘I/O消耗,相对于内存存取，I/O存取的消耗要高几个数量级,索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。为什么使用B-/+Tree，还跟磁盘存取原理有关。

### 局部性原理与磁盘预读

由于磁盘的存取速度与内存之间鸿沟,为了提高效率,要尽量减少磁盘I/O.磁盘往往不是严格按需读取，而是每次都会预读,磁盘读取完需要的数据,会顺序向后读一定长度的数据放入内存。而这样做的理论依据是计算机科学中著名的局部性原理：

```
当一个数据被用到时，其附近的数据也通常会马上被使用
程序运行期间所需要的数据通常比较集中
```

由于磁盘顺序读取的效率很高(不需要寻道时间，只需很少的旋转时间)，因此对于具有局部性的程序来说，预读可以提高I/O效率.预读的长度一般为页(page)的整倍数。

```
MySQL(默认使用InnoDB引擎),将记录按照页的方式进行管理,每页大小默认为16K(这个值可以修改).linux 默认页大小为4K
```

### 聚簇索引

数据库中的B+索引可以分为**聚簇索引**和**辅助索引**。

InnoDB存储引擎表是索引组织表，表中数据按照主键顺序存放。

聚簇索引就是按照每张表的主键构造一棵B+树，叶子节点中存放表的行记录数据，叶子节点间通过双向链表进行链接。每张表只能拥有一个聚簇索引。

聚簇索引由数据库自动生成。

如果没有主键，则按照下列规则来建聚簇索引

- 没有主键时，会用一个唯一且不为空的索引列做为主键，成为此表的聚簇索引
- 如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。



### 辅助索引

辅助索引中，叶子节点并不包含行记录的全部数据。叶子节点除了包含键值，还包含了指向该辅助索引相对应的行数据的主键索引的指针。这样，当通过辅助索引寻找数据时，InnoDB引擎会遍历辅助索引并通过该指针获得一个完整的行记录。每张表上可以有多个辅助索引。

索引优化原则
1. 索引覆盖 全值匹配
2. 最左匹配原则
3. 在索引列上做任何计算，或者使用函数、类型转换操作，都会导致索引失效而转向全表扫描。
4. 索引上使用了大于、小于等范围比较后，索引右边的列上的索引将失效。
5. 尽量使用覆盖索引，即使查询列表与索引列一致。尽量少使用select *
6. 对索引列上使用不等于操作（!= 或 <>）无法使用索引
7. 对索引列上使用is null, is not null操作也无法使用索引
8. like操作如果以%开头，将使索引失效而转向全表扫描。除非要查询的列覆盖索引
9. 字符串不加单引号时，索引会失效
10. or操作会使索引失效

## **最左前缀匹配原则**

在mysql建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，



## 分库分表

### 垂直切分

垂直切分常见有**垂直分库**和**垂直分表**两种。

#### 垂直分库

**垂直分库**就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。

#### 垂直分表

**垂直分表**是基于数据库中的表字段来进行的。业务中可能存在一些字段比较多的表，表中某些字段长度较大。这些长字段我们又只是偶尔需要用到。这时候我们就可以考虑将表进行垂直拆分了。将某些不常用的，但是长度又很大的字段拎出来放到另外一张表。

MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。另外数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。

### 垂直切分优缺点

优点：

1. 不同系统可以使用不同的库表，解决业务系统层面的耦合，业务清晰
2. 高并发场景下，垂直切分一定程度地提升IO、数据库连接数，缓解单机硬件资源的瓶颈

缺点：

1. 部分查询需要在业务代码逻辑里面做聚合，增加开发复杂度
2. 事务处理复杂，可能需要在业务代码层面做处理
3. 不能根本解决单表数据量过大的问题



## 水平切分

当业务难以更细粒度地进行垂直切分，或者切分后单表数据依然过大，存在单库读写、存储性能瓶颈时候，这时候就可以考虑水平切分了。

水平切分又可以分为**库内分表**和**分库分表**。是根据表内数据的内在逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。

### 库内分表

库内分表就是在同一个db上，将表按照某种条件拆分为多张表。

比如一张订单表，我们可以依据订单的日期，按月建表。一月份的订单放`month_201901`这张表，二月份的订单放`month_201902`这张表。

库内分表只解决单表数据量过大问题，但没有将表分布到不同机器上，所有请求还是在一台物理机上竞争cpu，内存，IO，对于减轻mysql负载压力来说帮助不大。

### 分库分表

分库分表就是将表不仅拆分，而且拆分到不同机器上。可以指定一张表的`shardKey`，然后对`shardKey`取hash，根据hash值将数据放到不同的数据库中。

这个可以解决单机物理资源的瓶颈问题。

### 分库分表优缺点

优点：

1. 不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力
2. 应用端改造较小，不需要拆分业务模块

缺点：

1. 跨分片的事务一致性较难保障，一般需要一层中间件，介于业务和db之间。对应腾讯云上的DCDB数据库所包含的Proxy层。
2. 跨库的join关联查询性能较差

### 分库分表带来的问题

分库分表能有效地缓解单机和单库带来的性能瓶颈和压力，突破网络IO、磁盘存储、CPU处理能力的瓶颈，同时也带来了一些问题。

1. 事务一致性问题

   当更新内容同时分布在不同库中，不可避免会带来跨库事务问题。跨分片事务也是分布式事务，没有简单的方案，一般可使用”XA协议”和”两阶段提交”处理。

   分布式事务能最大限度保证数据库操作的原子性。但在提交事务时需要协调多个节点，推后了提交事务的时间点，延长了事务的执行时间。导致事务在访问共享资源时发生冲突或死锁的概率增高。随着数据库节点的增多，这种趋势会越来越严重，从而成为系统在数据库层面上水平扩展的枷锁。

2. 跨节点关联查询 join 问题

   切分之前，系统中很多列表和详情页所需的数据可以通过sql join来完成。而切分之后，数据可能分布在不同的节点上，此时join带来的问题就比较麻烦了，考虑到性能，尽量避免使用join查询。

   解决这个问题的一些方法：

   - **全局表**：

     全局表，也可看做是”数据字典表”，就是系统中所有模块都可能依赖的一些表，为了避免跨库join查询，可以将这类表在每个数据库中都保存一份。这些数据通常很少会进行修改，所以也不担心一致性的问题。比如腾讯云上的DCDB，可以创建广播表，其实就是全局表。每个节点都有该表的全量数据，该表的所有操作都将广播到所有物理分片（set）中。

   - **字段冗余**

     一种典型的反范式设计，利用空间换时间，为了性能而避免join查询。例如：订单表保存userId时候，也将userName冗余保存一份，这样查询订单详情时就不需要再去查询”买家user表”了。

     但这种方法适用场景也有限，比较适用于依赖字段比较少的情况。而冗余字段的数据一致性也较难保证，就像上面订单表的例子，买家修改了userName后，是否需要在历史订单中同步更新呢？这也要结合实际业务场景进行考虑。

   - **数据组装**

     在系统层面，分两次查询，第一次查询的结果集中找出关联数据id，然后根据id发起第二次请求得到关联数据。最后将获得到的数据进行字段拼装。

     

     3. 全局主键避重问题

     在分库分表环境中，由于表中数据同时存在不同数据库中，主键平时使用的自增长将无用武之地，某个分区数据库自生成的ID无法保证全局唯一。因此需要单独设计全局主键，以避免跨库主键重复问题。有一些常见的主键生成策略。这里可以参阅[Leaf——美团点评分布式ID生成系统](https://tech.meituan.com/2017/04/21/mt-leaf.html)一文。





## MySQL中的日志

MySQL中的日志文件包括：重做日志、回滚日志、二进制日志、错误日志、慢查询日志、一般查询日志、中继日志。

### 事务日志

#### redo日志

redo日志记录事务执行后的状态，用来恢复未写入data file的，但事务已成功更新的数据，**保证事务的原子性、持久性**。尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo日志进行重做。redo日志是物理日志，记录物理页的修改。

#### undo日志

undo日志记录事务开始前的状态，用于事务失败时的回滚操作，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。**保证事务的一致性**。undo日志是逻辑日志，当回滚日志被使用时，它只会按照日志**逻辑地**将数据库中的修改撤销掉看，可以**理解**为，我们在事务中使用的每一条 `INSERT` 都对应了一条 `DELETE`，每一条 `UPDATE` 也都对应一条相反的 `UPDATE` 语句。

### 二进制日志

MySQL的二进制日志（binary log）是一个二进制文件，主要用于记录修改数据或有可能引起数据变更的MySQL语句。二进制日志（binary log）中记录了对MySQL数据库执行更改的所有操作，并且记录了语句发生时间、执行时长、操作数据等其它额外信息，但是它不记录SELECT、SHOW等那些不修改数据的SQL语句。二进制日志（binary log）主要用于数据库恢复和主从复制，以及审计（audit）操作。

binlog有三种格式：Statement、Row以及Mixed。

- 基于SQL语句的复制(statement-based replication,SBR)，
- 基于行的复制(row-based replication,RBR)， 
- 混合模式复制(mixed-based replication,MBR)。




## MySQL的主从复制

1.  Master将变更记录到二进制日志(binary log)中。
2.  Slave读取Master中的二进制日志，并将二进制日志拷贝到自己的中继日志中。
3.  Slave从中继日志读取事件，并重放其中的事件而更新slave的数据



## MySQL的读写分离

MySQL读写分离能提高系统性能的原因在于：

- 物理服务器增加，机器处理能力提升。拿硬件换性能。
- 主从只负责各自的读和写，极大程度缓解X锁和S锁争用。
- slave可以配置myiasm引擎，提升查询性能以及节约系统开销。
- master直接写是并发的，slave通过主库发送来的binlog恢复数据是异步。
- slave可以单独设置一些参数来提升其读的性能。
- 增加冗余，提高可用性。